{
  "learning_rate": 2e-4,
  "num_train_epochs": 5,
  "gradient_accumulation_steps": 4,
  "per_device_train_batch_size": 1,
  "lora_r": 16,
  "lora_alpha": 16,
  "max_seq_length": 8192,
  "load_in_4bit": true
}
